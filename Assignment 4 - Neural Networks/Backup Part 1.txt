"""
Assignment 4: Neural Network
Part 1

@author: Divyam Jain
         17HS20047
"""
#Importing some essential libraries

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import string
import math

#Importing the dataset

dataset = pd.read_csv('Assignment_4_data.txt', header=None, delimiter='\t')


"""------Preprocessing------"""

#Removing punctuations

dataset2 = pd.DataFrame(index=range(len(dataset)),columns=[0,1])
dataset2[0]=dataset[0]
for i in range(len(dataset)):
    dataset2[1][i]=dataset[1][i].translate(str.maketrans('', '', string.punctuation))
    
#Convert into lowercase
    
dataset2[1] = dataset2[1].apply(lambda x: " ".join(x.lower() for x in x.split()))

#Removing stopwords

stop = np.loadtxt("NLTK's list of english stopwords", dtype='str')
dataset2[1] = dataset2[1].apply(lambda x: " ".join(x for x in x.split() if x not in stop))

#Removing stop words spelt in another way
freq = pd.Series(' '.join(dataset2[1]).split()).value_counts()[:500]
freq_common = ['u', '2', 'im', 'ur', '4', 'dont', 'ü', 'r', 'da', 'd', 'wat', 'n', 'cant', 'thats', 'didnt', 'ive','dun', 'youre', 'v' ]

dataset2[1] = dataset2[1].apply(lambda x: " ".join(x for x in x.split() if x not in freq_common))

#Applying Porter Stemming

from nltk.stem import PorterStemmer

st=PorterStemmer()
dataset2[1] = dataset2[1].apply(lambda x: " ".join([st.stem(word) for word in x.split()]))

#Removing extremely rare words (that only appear once)
freq_rare = pd.Series(' '.join(dataset2[1]).split()).value_counts()
freq_rare = freq_rare[freq_rare==1]
freq_rare = list(freq_rare.index)
dataset2[1] = dataset2[1].apply(lambda x: " ".join(x for x in x.split() if x not in freq_rare))

#Tokenization

dataset3=dataset2.copy()
for i in range(len(dataset)):
    dataset3[1][i]=dataset2[1][i].split()
    
#Splitting into training set and test set
    
from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(dataset3[1].values, dataset3[0].values, test_size=0.2)

#Making the vector V

V = np.unique(np.array(' '.join(dataset2[1]).split()))

#Create an input and output representation

   #For training
rep_in = pd.DataFrame(0,index=V, columns = range(len(X_train)))

for i in range(len(X_train)):
    for j in X_train[i]:
        rep_in[i][j]=1

rep_out = np.ndarray((len(Y_train),1))
for i in range(len(Y_train)):
    if Y_train[i]=='spam':
        rep_out[i][0]=1
    else:
        rep_out[i][0]=0

   #For testing
reptest_in = pd.DataFrame(0,index=V, columns = range(len(X_test)))

for i in range(len(X_test)):
    for j in X_test[i]:
        reptest_in[i][j]=1

reptest_out = np.ndarray((len(Y_test),1))
for i in range(len(Y_test)):
    if Y_test[i]=='spam':
        reptest_out[i][0]=1
    else:
        reptest_out[i][0]=0      
                
#Building the neural network
        
n = 2   # n = number of layers

X = []
xx = np.ndarray(shape=(len(V)+1,1))
X.append(xx)
xx = np.ndarray(shape=(101,1))
X.append(xx)        
xx = np.ndarray(shape=(1,1))
X.append(xx)

#Weight initialiser

W = []
for i in range(1,n):
    W.append(np.random.randn(len(X[i-1]),len(X[i])-1)/100)
W.append(np.random.randn(len(X[n-1]),len(X[n]))/100)   

#Forward Pass

def forward(zero_layer):
    
    for i in range(0,n):
        X[i][0][0]=1
    
    X[0][1:,0]=zero_layer
    
    for i in range(1,n):
        for j in range(1,len(X[i])):
            X[i][j][0]=max(0,np.matmul(X[i-1].T,W[i-1][:,j-1])[0])
    
    for j in range(0,len(X[n])):
        #print('cccccccccccc')
        #print(np.matmul(X[n-1].T,W[n-1][:,j])[0])
        X[n][j][0]=1/(1+math.exp(-1*np.matmul(X[n-1].T,W[n-1][:,j])[0]))
 
#Back Propogation

def backward(actual):           
    delta = [None]*n
    #print('Holoooooo')
    #print(X[n][0][0])
    if (X[n][0][0]==1 and actual==1) or (X[n][0][0]==0 and actual==0):
        error=0
    else:
        error = -(actual*math.log(X[n][0][0])+(1-actual)*math.log(1-X[n][0][0]))

    delta[n-1]=np.ndarray(shape=(1,1))

    delta[n-1][0][0]=(X[n][0][0]-actual)
    
    for i in range(1,n):
        delta[i-1]=np.ndarray(shape=(len(X[i])-1,1))
        for j in range(1,len(X[i])):
            delta[i-1][j-1][0]=0
            if X[i][j][0]!=0:
                for k in range(0,len(delta[i])):
                    delta[i-1][j-1][0]+=delta[i][k][0]*W[i][j][k]
                    
    alpha = 0.1 #learning rate
    for i in range(0,len(W)):
        for j in range(0,len(W[i])):
            for k in range(0,len(delta[i])):
                W[i][j][k]=W[i][j][k]-alpha*X[i][j][0]*delta[i][k][0]
                
#Training
                
def training (epochs):
    
    for i in range(epochs):
        for j in range(len(X_train)):
            print("Epoch:",i,"Sample:",j)
            forward(rep_in[j])
            backward(rep_out[j][0])
        training_accuracy[i], test_accuracy[i] = accuracy(i)
            
        
threshold = 0.5
training_accuracy = np.zeros(10) 
test_accuracy = np.zeros(10)
predicted_train = [[],[],[],[],[],[],[],[],[],[]]  
predicted_test = [[],[],[],[],[],[],[],[],[],[]]      

def accuracy(index):
    
    #Training Accuracy
    for i in range(len(X_train)):
            forward(rep_in[i])
            predicted_train[index].append(X[n][0][0])
    
    for i in range(len(predicted_train[index])):
        if predicted_train[index][i]>threshold:
            predicted_train[index][i]=1
        else:
            predicted_train[index][i]=0
    
    count = 0
    for i in range(len(predicted_train[index])):
        if predicted_train[index][i]==rep_out[i][0]:
            count+=1
    training_accuracy = count/len(predicted_train[index])*100
    
    #Test Accuracy
    
    for i in range(len(X_test)):
            forward(reptest_in[i])
            predicted_test[index].append(X[n][0][0])
    
    for i in range(len(predicted_test[index])):
        if predicted_test[index][i]>threshold:
            predicted_test[index][i]=1
        else:
            predicted_test[index][i]=0
    
    count = 0
    for i in range(len(predicted_test[index])):
        if predicted_test[index][i]==reptest_out[i][0]:
            count+=1
    test_accuracy = count/len(predicted_test[index])*100
    
    return training_accuracy,test_accuracy
            
#Running the network
    
training(10)

#Plotting the graph

plt.plot([1,2,3,4,5,6,7,8,9,10], training_accuracy, color = 'red')
plt.plot([1,2,3,4,5,6,7,8,9,10], test_accuracy, color = 'blue')
plt.title('Training accuracy and Test accuracy for epoch 1 to 10')
plt.xlabel('Number of epochs')
plt.ylabel('Accuracy')
plt.legend(labels=('Training accuracy', 'Test accuracy'))
plt.show()


#To calculate training and test set errors
'''
pred_train = []
pred_test = []
def acc():
    
    #Training Accuracy
    for i in range(len(X_train)):
            forward(rep_in[i])
            pred_train.append(X[n][0][0])
    error=0
    for i in range(len(pred_train)):
        if (pred_train[i]==1 and rep_out[i][0]==1 ) or (pred_train[i]==0 and rep_out[i][0]==0):
            error+=0
        else:
            error += -(rep_out[i][0]*math.log(pred_train[i])+(1-rep_out[i][0])*math.log(1-pred_train[i]))
            
    train_error = error/len(X_train)
    
    #Test Accuracy
    
    for i in range(len(X_test)):
            forward(reptest_in[i])
            pred_test.append(X[n][0][0])
    
    error=0
    for i in range(len(pred_test)):
        if (pred_test[i]==1 and reptest_out[i][0]==1 ) or (pred_test[i]==0 and reptest_out[i][0]==0):
            error+=0
        else:
            error += -(reptest_out[i][0]*math.log(pred_test[i])+(1-reptest_out[i][0])*math.log(1-pred_test[i]))
            
    test_error = error/len(X_test)
    
    return train_error,test_error
        
train_error,test_error = acc()
'''


            
 



















